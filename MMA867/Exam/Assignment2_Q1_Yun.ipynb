{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "\n",
    "#Build the path for the Airfares data file\n",
    "data_path = osp.join(osp.curdir,'banks.csv')\n",
    "\n",
    "#Use the read_excel function to pull data from the 'Airfares'\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "Financial Condition      int64\nTotExp/Assets          float64\nTotLns&Lses/Assets     float64\ndtype: object"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "            Obs  Financial Condition  TotCap/Assets  TotExp/Assets  \\\ncount  20.00000            20.000000      20.000000      20.000000   \nmean   10.50000             0.500000       9.320000       0.104500   \nstd     5.91608             0.512989       4.797214       0.026052   \nmin     1.00000             0.000000       1.000000       0.070000   \n25%     5.75000             0.000000       7.125000       0.080000   \n50%    10.50000             0.500000       9.200000       0.100000   \n75%    15.25000             1.000000      11.300000       0.120000   \nmax    20.00000             1.000000      20.500000       0.160000   \n\n       TotLns&Lses/Assets  \ncount           20.000000  \nmean             0.628500  \nstd              0.159779  \nmin              0.300000  \n25%              0.525000  \n50%              0.640000  \n75%              0.722500  \nmax              1.020000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Obs</th>\n      <th>Financial Condition</th>\n      <th>TotCap/Assets</th>\n      <th>TotExp/Assets</th>\n      <th>TotLns&amp;Lses/Assets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>20.00000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>10.50000</td>\n      <td>0.500000</td>\n      <td>9.320000</td>\n      <td>0.104500</td>\n      <td>0.628500</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.91608</td>\n      <td>0.512989</td>\n      <td>4.797214</td>\n      <td>0.026052</td>\n      <td>0.159779</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.070000</td>\n      <td>0.300000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.75000</td>\n      <td>0.000000</td>\n      <td>7.125000</td>\n      <td>0.080000</td>\n      <td>0.525000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>10.50000</td>\n      <td>0.500000</td>\n      <td>9.200000</td>\n      <td>0.100000</td>\n      <td>0.640000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>15.25000</td>\n      <td>1.000000</td>\n      <td>11.300000</td>\n      <td>0.120000</td>\n      <td>0.722500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>20.00000</td>\n      <td>1.000000</td>\n      <td>20.500000</td>\n      <td>0.160000</td>\n      <td>1.020000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "Obs                    0\nFinancial Condition    0\nTotCap/Assets          0\nTotExp/Assets          0\nTotLns&Lses/Assets     0\ndtype: int64"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if there is null data in the dataset\n",
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "#Split data into train and test, also we need to standardize the predictor variable before fitting in the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df['Financial Condition']\n",
    "X = df[['TotExp/Assets','TotLns&Lses/Assets']]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled,y,train_size=0.7,random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             OLS Regression Results                            \n",
      "===============================================================================\n",
      "Dep. Variable:     Financial Condition   R-squared:                       0.500\n",
      "Model:                             OLS   Adj. R-squared:                  0.409\n",
      "Method:                  Least Squares   F-statistic:                     5.501\n",
      "Date:                 Sun, 21 May 2023   Prob (F-statistic):             0.0221\n",
      "Time:                         13:00:08   Log-Likelihood:                -5.1642\n",
      "No. Observations:                   14   AIC:                             16.33\n",
      "Df Residuals:                       11   BIC:                             18.25\n",
      "Df Model:                            2                                         \n",
      "Covariance Type:             nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.5252      0.108      4.859      0.001       0.287       0.763\n",
      "x1             0.3083      0.113      2.738      0.019       0.060       0.556\n",
      "x2             0.1748      0.102      1.712      0.115      -0.050       0.400\n",
      "==============================================================================\n",
      "Omnibus:                        6.035   Durbin-Watson:                   2.185\n",
      "Prob(Omnibus):                  0.049   Jarque-Bera (JB):                2.981\n",
      "Skew:                          -1.045   Prob(JB):                        0.225\n",
      "Kurtosis:                       3.862   Cond. No.                         1.27\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunxu/.conda/envs/test_project/lib/python3.10/site-packages/scipy/stats/_stats_py.py:1736: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=14\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "X_train_1 = sm.add_constant(X_train)\n",
    "\n",
    "model = sm.OLS(y_train, X_train_1).fit()\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(C=1e+42, solver='liblinear')",
      "text/html": "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1e+42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1e+42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#using the liblinear version this time since the dataset is pretty small\n",
    "logit_reg = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
    "logit_reg.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept  0.1635275101912511\n",
      "       TotExp/Assets  TotLns&Lses/Assets\n",
      "coeff       2.133089            0.967546\n",
      "AIC 38.27670558308775\n"
     ]
    }
   ],
   "source": [
    "from dmba.metric import AIC_score\n",
    "print('intercept ', logit_reg.intercept_[0])\n",
    "print(pd.DataFrame({'coeff': logit_reg.coef_[0]}, index=X.columns).transpose())\n",
    "print('AIC', AIC_score(y_test, logit_reg.predict(X_test), df = len(X_train)\n",
    "+ 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.9286)\n",
      "\n",
      "       Prediction\n",
      "Actual 0 1\n",
      "     0 5 1\n",
      "     1 0 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dmba import classificationSummary\n",
    "\n",
    "y_pred = model.predict(X_train_1)\n",
    "cutoff = 0.5\n",
    "y_pred_classes = np.zeros_like(y_pred)\n",
    "y_pred_classes[y_pred > cutoff] = 1\n",
    "\n",
    "classificationSummary(y_train, y_pred_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.9286)\n",
      "\n",
      "       Prediction\n",
      "Actual 0 1\n",
      "     0 5 1\n",
      "     1 0 8\n"
     ]
    }
   ],
   "source": [
    "from dmba import classificationSummary\n",
    "classificationSummary(y_train, logit_reg.predict(X_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "B0 = logit_reg.intercept_[0]\n",
    "B1 = logit_reg.coef_[0][0]\n",
    "B2 = logit_reg.coef_[0][1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit =  0.1635275101912511 + 2.133088779833814  * TotExp/Assets + 0.9675463795900938 * TotLns&Lses/Assets\n",
      "Odds = exp( 0.1635275101912511 + 2.133088779833814  * TotExp/Assets + 0.9675463795900938 * TotLns&Lses/Assets\n",
      "Probability = 1/1 +exp(-( 0.1635275101912511 + 2.133088779833814  * TotExp/Assets + 0.9675463795900938 * TotLns&Lses/Assets ))\n"
     ]
    }
   ],
   "source": [
    "print('Logit = ',B0,'+',B1,' * TotExp/Assets +', B2,'* TotLns&Lses/Assets')\n",
    "print('Odds = exp(',B0,'+',B1,' * TotExp/Assets +', B2,'* TotLns&Lses/Assets')\n",
    "print('Probability = 1/1 +exp(-(',B0,'+',B1,' * TotExp/Assets +', B2,'* TotLns&Lses/Assets ))')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#1:Write the estimated equation that associates the financial condition of a bank with its two predictors in three formats:\n",
    "A.\tThe logit as a function of the predictors\n",
    "B.\tThe odds as a function of the predictors\n",
    "C.\tThe probability as a function of the predictors\n",
    "\n",
    "\n",
    "1.By run the above logistic regression, we have the logit as a function of the predictors: Financial Conditions = 0.163528 + 2.133089 * TotExp/Assets + 0.967546 *TotLns&Lses/Assets\n",
    "the odds function would be:Financial Conditions = exp(0.163528 + 2.133089 * TotExp/Assets + 0.967546 *TotLns&Lses/Assets)\n",
    "the probability function would be:p(Financial Conditions =1) =1/(1+ exp(-(0.163528 + 2.133089 * TotExp/Assets + 0.967546 *TotLns&Lses/Assets)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "#2 Consider a new bank whose total loans and leases/assets ratio = 0.6 and total expenses/assets ratio = 0.11. From your logistic regression model, estimate the following four quantities for this bank (use R to do all the intermediate calculations; show your final answers to four decimal places): the logit, the odds, the probability of being financially weak, and the classification of the bank (use cutoff = 0.5)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "Total_loans_and_Leases_Asstes = 0.6\n",
    "Total_expense_Assets = 0.11"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit: 0.9787\n"
     ]
    }
   ],
   "source": [
    "Logit = B0 + B1 * Total_expense_Assets +B2 * Total_loans_and_Leases_Asstes\n",
    "print(f'Logit: {Logit:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds: 2.6610\n"
     ]
    }
   ],
   "source": [
    "odds = np.exp(Logit)\n",
    "print(f'Odds: {odds:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: 0.7268\n"
     ]
    }
   ],
   "source": [
    "probability = 1 / (1 + np.exp(-Logit))\n",
    "print(f'Probability: {probability:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bank is financially weak\n"
     ]
    }
   ],
   "source": [
    "if(probability > 0.5):\n",
    "    print('The bank is financially weak')\n",
    "else:\n",
    "    print('The bank is financially strong')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corresponding odd cutoff is 1.0\n",
      "The corresponding logit cutoff is 0.0\n"
     ]
    }
   ],
   "source": [
    "#3.\tThe cutoff value of 0.5 is used in conjunction with the probability of being financially weak. Compute the threshold that should be used if we want to make a classification based on the odds of being financially weak, and the threshold for the corresponding logit.\n",
    "odds_cutoff = cutoff/(1-cutoff)\n",
    "print('The corresponding odd cutoff is', odds_cutoff)\n",
    "print('The corresponding logit cutoff is', np.log(odds_cutoff))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We know that the logit function can also be written as : 1-p/p  = 1/ odds function, thus the odds function can be revised as: odds function = p/1-p which is the cutoff we need to calculate. based on the cutoff probability is 0.5, we calculated the corresponding odds cut off is 1. the corresponding logit is the ln(odds_cutoff), which is 0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the coefficient for total loans & leases to total assets is 0.9675463795900938\n",
      "the coefficient for total loans & leases to total assetes in terms of odds is -0.03299191766634785\n"
     ]
    }
   ],
   "source": [
    "#4.\tInterpret the estimated coefficient for the total loans & leases to total assets ratio (TotLns&Lses/Assets) in terms of the odds of being financially weak.\n",
    "print('the coefficient for total loans & leases to total assets is',B2)\n",
    "print('the coefficient for total loans & leases to total assetes in terms of odds is', np.log(B2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The coefficient of total loans & leases to total assets is 0.9675 which represents, that total loans & leases to total assets ratio increased by 1, the log of the bank being financially weak increases. in terms of odds,the coefficient is -0.033, which means the decreasing on the coefficient that the total loans & leases to total assets ratio decreased by 1, the odds of the bank being financially strong is increasing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#5.\tWhen a bank that is in poor financial condition is misclassified as financially strong, the misclassification cost is much higher than when a financially strong bank is misclassified as weak. To minimize the expected cost of misclassification, should the cutoff value for classification (which is currently at 0.5) be increased or decreased?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When the cost of misclassfication is high, we should reduce the false negative, since the strong bank is misclassified as weak. To reduce the false negative, we should lower the cutoff value. In this way, it increased the probability of predicting a bank as weak which will have higher chance to have more actual weak bank and reduce the chance of misclassifying the strong banks to the weak."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
